{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommended Preprocessing\n",
    "*Written by Luke Chang*\n",
    "\n",
    "There are currently no agreed upon conventions for preprocessing naturalistic neuroimaging data. In this tutorial, we show how we preprocessed the datasets used in all of our tutorials. This tutorial assumes you have some basic knowledge of preprocessing. If you have questions about the specific details, we enourage you to read other tutorials, such as the preprocessing [overview](https://dartbrains.org/features/notebooks/7_Preprocessing.html) from the Dartbrains course.\n",
    "\n",
    "In our [lab](http://cosanlab.com/), we perform standard realignment and spatial normalization using a custom [nipype](https://nipype.readthedocs.io/en/latest/) [workflow](https://github.com/cosanlab/cosanlab_preproc) or [fmriprep](https://fmriprep.org/en/stable/). We also perform basic denoising by removing global and multivariate spikes, average CSF activity, linear/quadratic trends, and 24 motion covariates (e.g., 6 centered realignment, their squares, derivative, and squared derivatives). We are very cautious about performing high-pass filtering as many of the effects we are interested in occur in [slower frequencies](https://www.biorxiv.org/content/early/2018/12/16/487892). We find that including average activity from a CSF mask helps a lot in reducing different types of physiological and motion related artifacts. We typically apply spatial smoothing, but depending on the question we don't always perform this step. For spatial feature selection, we rarely use searchlights and instead tend to use parcellations. This allows us to quickly prototype analysis ideas using smaller numbers of parcels (e.g., n=50) and then increase the number if we want greater spatial specificity. Starting with K=50 parcellation speeds up our computation by several orders of magnitude compared to voxelwise or searchlight approaches. In addition, the bonferroni correction for multiple comparisons is p < 0.001, which is a reasonable threshold to observe statistically significant results with our research questions. We usually use a [parcellation](https://neurovault.org/collections/2099/) scheme that we developed with [Tal Yarkoni](https://talyarkoni.org/) based on meta-analytic coactivation using the neurosynth database. Selecting the right spatial features for a particular question is a surprisingly under-appreciated topic. See our [paper](https://osf.io/4exrn/?show=view) discussing the costs and benefits of different spatial feature selection strategies. Head motion is also an important consideration with naturalistic designs particularly with long scanning sessions or when participants actively speak in the scanner. We have recently evaluated the [efficacy](https://www.biorxiv.org/content/10.1101/2020.03.27.012310v1) of using [caseforge headcases](https://caseforge.co/?gclid=CjwKCAjw8df2BRA3EiwAvfZWaGA5Jz_RABlW6vKdvdjJCULwaeFW3BHMI-FkSLX27DbS4B7LlUHOrhoCYKIQAvD_BwE) in reducing head motion in naturalistic viewing studies. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naturalistic Data Preprocessing\n",
    "For the two datasets we are using in this course (Sherlock & Paranoia), we performed very minimal preprocessing. First, we used [fmriprep](https://fmriprep.readthedocs.io/en/stable/) to realign and spatially normalize the data. If you don't have strong opinions about the details of preprocessing, we highly recommend using fmriprep, which is developed and maintained by a team at the [Center for Reproducible Research](http://reproducibility.stanford.edu/) led by Russ Poldrack and Chris Gorgolewski. Fmriprep was designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols, requires minimal user input, and provides easily interpretable and comprehensive error and output reporting. We like that they share a docker container with all of the relevant software packages, it is very simple to run, and that there is a large user base that actively report bugs so that it is constantly improving.\n",
    "\n",
    "After preprocessing with fmriprep, we smoothed the data (fwhm=6mm) and performed basic voxelwise denoising using a GLM. This entails including the 6 realignment parameters, their squares, their derivatives, and squared derivatives. We also include dummy codes for spikes identified from global signal outliers and outliers identified from frame differencing (i.e., temporal derivative). We chose to not perform high-pass filtering and instead include linear & quadratic trends, and average CSF activity to remove additional physiological and scanner artifacts. Finally, to save space, we downsampled to Float32 precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltools.stats import regress, zscore\n",
    "from nltools.data import Brain_Data, Design_Matrix\n",
    "from nltools.stats import find_spikes \n",
    "from nltools.mask import expand_mask\n",
    "\n",
    "def make_motion_covariates(mc, tr):\n",
    "    z_mc = zscore(mc)\n",
    "    all_mc = pd.concat([z_mc, z_mc**2, z_mc.diff(), z_mc.diff()**2], axis=1)\n",
    "    all_mc.fillna(value=0, inplace=True)\n",
    "    return Design_Matrix(all_mc, sampling_freq=1/tr)\n",
    "\n",
    "base_dir = '/Volumes/Engram/Data/Sherlock/fmriprep'\n",
    "\n",
    "fwhm=6\n",
    "tr = 1.5\n",
    "outlier_cutoff = 3\n",
    "\n",
    "file_list = [x for x in glob.glob(os.path.join(base_dir, '*/func/*preproc*gz')) if 'denoised' not in x] \n",
    "for f in file_list:\n",
    "    sub = os.path.basename(f).split('_')[0]\n",
    "\n",
    "    data = Brain_Data(f)\n",
    "    smoothed = data.smooth(fwhm=fwhm)\n",
    "\n",
    "    spikes = smoothed.find_spikes(global_spike_cutoff=outlier_cutoff, diff_spike_cutoff=outlier_cutoff)\n",
    "    covariates = pd.read_csv(glob.glob(os.path.join(base_dir, sub, 'func', '*tsv'))[0], sep='\\t')\n",
    "    mc = covariates[['trans_x','trans_y','trans_z','rot_x', 'rot_y', 'rot_z']]\n",
    "    mc_cov = make_motion_covariates(mc, tr)\n",
    "    csf = covariates['csf'] # Use CSF from fmriprep output\n",
    "    dm = Design_Matrix(pd.concat([csf, mc_cov, spikes.drop(labels='TR', axis=1)], axis=1), sampling_freq=1/tr)\n",
    "    dm = dm.add_poly(order=2, include_lower=True) # Add Intercept, Linear and Quadratic Trends\n",
    "\n",
    "    smoothed.X = dm\n",
    "    stats = smoothed.regress()\n",
    "    stats['residual'].data = np.float32(stats['residual'].data) # cast as float32 to reduce storage space\n",
    "    stats['residual'].write(os.path.join(base_dir, sub, 'func', f'{sub}_denoise_smooth{fwhm}mm_task-sherlockPart1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also saved the cropped denoised viewing data as an hdf5 file to speed up loading times when using nltools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T03:33:26.139279Z",
     "start_time": "2020-06-08T03:30:20.233843Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = '/Volumes/Engram/Data/Sherlock/fmriprep'\n",
    "\n",
    "for scan in ['Part1', 'Part2']:\n",
    "    file_list = glob.glob(os.path.join(data_dir, '*', 'func', f'*crop*{scan}*nii.gz'))\n",
    "    for f in file_list:\n",
    "        data = Brain_Data(f)\n",
    "        data.write(f\"{f.split('.nii.gz')[0]}.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have also precomputed average activations within a whole brain parcellation (n=50) for some of the tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T04:17:17.821438Z",
     "start_time": "2020-06-08T03:55:43.603710Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = '/Volumes/Engram/Data/Sherlock/fmriprep'\n",
    "\n",
    "mask = Brain_Data('http://neurovault.org/media/images/2099/Neurosynth%20Parcellation_0.nii.gz')\n",
    "\n",
    "for scan in ['Part1', 'Part2']:\n",
    "    file_list = glob.glob(os.path.join(data_dir, '*', 'func', f'*crop*{scan}*hdf5'))\n",
    "    for f in file_list:\n",
    "        sub = os.path.basename(f).split('_')[0]\n",
    "        print(sub)\n",
    "        data = Brain_Data(f)\n",
    "        roi = data.extract_roi(mask)\n",
    "        pd.DataFrame(roi.T).to_csv(os.path.join(os.path.dirname(f), f\"{sub}_{scan}_Average_ROI_n50.csv\" ), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommended reading\n",
    "\n",
    "* Jolly, E., Sadhukha, S., & Chang, L. J. (2020). Custom-molded headcases have limited efficacy in reducing head motion for fMRI. BioRxiv.\n",
    "\n",
    "* Jolly, E., & Chang, L.J. (2020). Multivariate spatial feature selection in fMRI. OSF.\n",
    "\n",
    "* Chang, L. J., Jolly, E., Cheong, J. H., Rapuano, K., Greenstein, N., Chen, P. H. A., & Manning, J. R. (2018). Endogenous variation in ventromedial prefrontal cortex state dynamics during naturalistic viewing reflects affective experience. BioRxiv, 487892."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T02:34:11.627082Z",
     "start_time": "2020-05-15T02:34:11.622577Z"
    }
   },
   "source": [
    "Have thoughts on preprocessing?  Please share them as a github [issue](https://github.com/naturalistic-data-analysis/naturalistic_data_analysis/issues) on our jupyter-book repository and we can incorporate them into the notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
